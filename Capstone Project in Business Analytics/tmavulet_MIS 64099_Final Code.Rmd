---
title: "MIS 64099- Capstone Project for Business Analytics Final Result"
author: "Tejasvini Mavuleti"
date: "2022-08-03"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Install R packages

```{r install_rmarkdown, eval=FALSE}
install.packages("randomForest")
install.packages("corrplot")
install.packages("caretEnsemble")
install.packages("lsr")
install.packages("rpart")
install.packages("caret")
install.packages("e1071")
```

## Exploratory Data Analysis

```{r }
options(warm=-1)
# Data splitting
library(rsample)  

# Data visualization
library(lubridate)
library(ggplot2)  

# Data transformation
library(randomForest)
library(dplyr) 

# Caret libraries
library(rpart)
library(caret) 
library(caretEnsemble)
library(e1071)
library(corrplot)
library(mlbench)
library(pROC)
library(lsr)
```

## Functions to clean datasets

# Read datasets from the csv file
```{r }
clean_dataset <- function() {
  dataset = "C:/Users/mavul/OneDrive/Desktop/Health care data.csv"
  if (file.exists(dataset)) {
    alldata <- read.csv(file=dataset, header = T)
  }
  return(alldata)
}
```

# Convert and grouping age groups
The four groups are (0-25, 26-40, 41-50, 50-65, 65+)
```{r }
age <- function(dob, age.day = today(), units = "years", floor = TRUE) {
  calc.age = interval(dob, age.day) / duration(num = 1, units = units)
  if (floor) return(as.integer(floor(calc.age)))
  
  return(calc.age)
}
age_group <- function(a) {
  ifelse(a<25,25, ifelse(a<40, 40, ifelse(a<50,50,65)))
}
```

# Match and group the countries based on the patients ethnic group
```{r }
e_europe <- c('Ukraine','Russia','Poland','Czech Republic','Hungary')
w_europe <- c('Austria','Belgium','France','Germany','Italy','Netherlands','Portugal','Spain','Switzerland')
n_europe <- c('Sweden', 'Finland', 'Denmark')
c_europe <- c('England','Scotland','Ireland')
ethnic_group <- function(country) {
  ifelse((country %in% e_europe), 'e_europe',
         ifelse((country %in% w_europe) ,'w_europe',
                ifelse((country %in% n_europe), 'n_europe',
                       ifelse((country %in% c_europe), 'c_europe',
                              country))))
}
```

# Remove the patient ids from the dataset
```{r}
patients <- clean_dataset()
patients <- patients[,-1]
str(patients)
summary(patients)
```
From the summary, there are no N/A or missing data in the dataset. We need to work on the education column values by fixing the misspelled words

```{r}
patients$education <- ifelse(patients$education == 'highscool', as.character('highschool'), as.character(patients$education))
patients$education <- ifelse(as.factor(patients$education) == 'phD/MD', as.character('phd/md'), as.character(patients$education))
patients$education <- as.factor(patients$education)
```

# Group the ancestry countries to ethnic groups
```{r}
patients$ancestry <- as.factor(ethnic_group(patients$ancestry))
```

# Convert the date of birth into age and group them into 25-40-50-65
```{r}
patients$age <- age(patients$dob)
patients$age <- age_group(age(patients$dob))
```

We need to change places to move each disease to a seperate column with binary values (0 is the patient with not disease and 1 is the patient who has the disease)

```{r}
binary_value <- function(value, compare_to) {
  ifelse(value==compare_to,1,0)
}

patients$prostate_cancer <- binary_value(patients$disease,'prostate cancer')
patients$skin_cancer <- binary_value(patients$disease,'skin cancer')
patients$breast_cancer <- binary_value(patients$disease,'breast cancer')
patients$hiv_aids <- binary_value(patients$disease,'HIV/AIDS')
patients$diabetes <- binary_value(patients$disease,'diabetes')
patients$heart_disease <- binary_value(patients$disease,'heart disease')
patients$hypertension <- binary_value(patients$disease,'hypertension')
patients$endometriosis <- binary_value(patients$disease,'endometriosis')
patients$multiple_sclerosis <- binary_value(patients$disease,'multiple sclerosis')
patients$schizophrenia <- binary_value(patients$disease,'schizophrenia')
patients$kidney_disease <- binary_value(patients$disease,'kidney disease')
patients$gastritis <- binary_value(patients$disease,'gastritis')
patients$alzheimer <- binary_value(patients$disease,'Alzheimer disease')
str(patients)
```

## Barplots for the distribution of the categorical columns to count the total number of diseases in the dataset
```{r}
par(las=2) # make label text perpendicular to axis
par(mar=c(5,8,4,2)) # increase y-axis margin.
disease_counts <- table(patients$disease)
barplot(sort(disease_counts, decreasing = TRUE), main="Disease Names", 
        xlab="Diseases Frequency", 
        col=rainbow(15),
        horiz=TRUE,
        cex.names=0.8,
        xlim = c(0, 350))
```

# Gender breakdown
```{r}
gender_counts <- table(patients$gender)
barplot(sort(gender_counts, decreasing = TRUE), main="Gender", 
        col=rainbow(15), las=1)
```

# Age breakdown
```{r}
age_breaks <- c(0,25,40,65,100)
tags <- c("[0-25)","[26-40)", "[41-65)", "[65+)")
age_group_tags <- cut(patients$age, 
                  breaks=age_breaks, 
                  include.lowest=TRUE, 
                  right=FALSE, 
                  labels=tags)
summary(age_group_tags)
#age_counts <- table(patients$age)
age_counts <- table(age_group_tags)
barplot(sort(age_counts, decreasing = TRUE), main="Age",
        col=rainbow(15), las=1)
```

# Gender and disease breakdown
```{r}
disease_name = c(as.character(unique(patients$disease)))
for (d in disease_name) {
  gender_disease_counts <- subset(patients, patients$disease == d)
  gender_disease_counts <- table(gender_disease_counts$gender)
  barplot(gender_disease_counts, main=d, col=rainbow(15), las=1)
}
```

# Disease and ancestry breakdown
```{r}
for (d in disease_name) {
  ancestry_disease_counts <- subset(patients, patients$disease == d)
  ancestry_disease_counts <- table(ancestry_disease_counts$ancestry)
  barplot(ancestry_disease_counts, main=d, col=rainbow(15), las=1)
}
```

## Barplots for dependent variables

# Age and disease distribution
```{r}
for (d in disease_name) {
  age_disease_counts <- subset(patients, patients$disease == d)
  #age_disease_counts <- table(age_disease_counts$age_group_tags)
  age_disease_counts <- table(age_disease_counts$age)
  barplot(age_counts, main=d, col=rainbow(15), las=1)
}
```

# Employment and disease distribution
```{r}
for (d in disease_name) {
  emp_disease_counts <- subset(patients, patients$disease == d)
  emp_disease_counts <- table(emp_disease_counts$employment_status)
  barplot(emp_disease_counts, main=d, col=rainbow(15), las=1)
}
```

# People with disease and children 
```{r}
for (d in disease_name) {
  child_disease_counts <- subset(patients, patients$disease == d)
  child_disease_counts <- table(child_disease_counts$children)
  barplot(child_disease_counts, main=d, col=rainbow(15), las=1)
}
```

# Average commute and disease breakdown
```{r}
for (d in disease_name) {
  comm_disease_counts <- subset(patients, patients$disease == d)
  comm_disease_counts <- table(comm_disease_counts$avg_commute)
  barplot(comm_disease_counts, main=d, col=rainbow(15), las=1)
}
```

# Internet usage and disease breakdown
```{r}
for (d in disease_name) {
  net_disease_counts <- subset(patients, patients$disease == d)
  net_disease_counts <- table(net_disease_counts$daily_internet_use)
  barplot(net_disease_counts, main=d, col=rainbow(15), las=1)
}
```

# Available vehicles and disease
```{r}
for (d in disease_name) {
  veh_disease_counts <- subset(patients, patients$disease == d)
  veh_disease_counts <- table(veh_disease_counts$available_vehicles)
  barplot(veh_disease_counts, main=d, col=rainbow(15), las=1)
}
```

# Military service and disease distribution
```{r}
for (d in disease_name) {
  mil_disease_counts <- subset(patients, patients$disease == d)
  mil_disease_counts <- table(mil_disease_counts$military_service)
  barplot(mil_disease_counts, main=d, col=rainbow(20), las=1)
}
```

## Feature Selection

Feature selection using Chi-squared method after splitting and balancing the dataset for three diseases (Alzheimer, hypertension, skin cancer)

```{r}
alzheimer_set <- select(patients, gender, age, employment_status, education, marital_status, ancestry, available_vehicles, avg_commute,zipcode, children,daily_internet_use,military_service, alzheimer)
FeatureTrain <- sample(nrow(alzheimer_set), 0.7*nrow(alzheimer_set), replace = FALSE)
FeatureTrainSet <- alzheimer_set[FeatureTrain,]
FeatureTestSet <- alzheimer_set[-FeatureTrain,]
response <- as.factor(patients$alzheimer)
input <- select(patients, gender, age, employment_status, education, marital_status, ancestry, available_vehicles, avg_commute,zipcode, children,daily_internet_use,military_service)
ubOver <- function(X, Y, k = 0, verbose=TRUE) {
}
data <- ubOver(X=input, Y=response)
alzheime_os_dataset <- cbind(data$X, class=data$Y)
chisq.test(alzheime_os_dataset$class, alzheime_os_dataset$gender)
chisq.test(alzheime_os_dataset$class, alzheime_os_dataset$age)
chisq.test(alzheime_os_dataset$class, alzheime_os_dataset$education)
chisq.test(alzheime_os_dataset$class, alzheime_os_dataset$marital_status)
chisq.test(alzheime_os_dataset$class, alzheime_os_dataset$zipcode)
chisq.test(alzheime_os_dataset$class, alzheime_os_dataset$employment_status)
chisq.test(alzheime_os_dataset$class, alzheime_os_dataset$children)
chisq.test(alzheime_os_dataset$class, alzheime_os_dataset$ancestry)
chisq.test(alzheime_os_dataset$class, alzheime_os_dataset$avg_commute)
chisq.test(alzheime_os_dataset$class, alzheime_os_dataset$daily_internet_use)
chisq.test(alzheime_os_dataset$class, alzheime_os_dataset$available_vehicles)
chisq.test(alzheime_os_dataset$class, alzheime_os_dataset$military_service)
alzheime_os_dataset %>%
  filter(class == "1") %>%
  select_if(is.numeric) %>%
  cor() %>%
  corrplot::corrplot()
```

Feature the selection Hypertension using Chi-squared
```{r}
hypertension_set <- select(patients, gender, age, employment_status, education, marital_status, ancestry, available_vehicles, avg_commute,zipcode, children,daily_internet_use,military_service, hypertension)
FeatureTrain <- sample(nrow(hypertension_set), 0.7*nrow(hypertension_set), replace = FALSE)
FeatureTrainSet <- hypertension_set[FeatureTrain,]
FeatureTestSet <- hypertension_set[-FeatureTrain,]
response <- as.factor(patients$hypertension)
input <- select(patients, gender, age, employment_status, education, marital_status, ancestry, available_vehicles, avg_commute,zipcode, children,daily_internet_use,military_service)
data <- ubOver(X=input, Y=response)
hypertension_os_dataset <- cbind(data$X, class=data$Y)
chisq.test(hypertension_os_dataset$class, hypertension_os_dataset$gender)
chisq.test(hypertension_os_dataset$class, hypertension_os_dataset$age)
chisq.test(hypertension_os_dataset$class, hypertension_os_dataset$education)
chisq.test(hypertension_os_dataset$class, hypertension_os_dataset$marital_status)
chisq.test(hypertension_os_dataset$class, hypertension_os_dataset$zipcode)
chisq.test(hypertension_os_dataset$class, hypertension_os_dataset$employment_status)
chisq.test(hypertension_os_dataset$class, hypertension_os_dataset$children)
chisq.test(hypertension_os_dataset$class, hypertension_os_dataset$ancestry)
chisq.test(hypertension_os_dataset$class, hypertension_os_dataset$avg_commute)
chisq.test(hypertension_os_dataset$class, hypertension_os_dataset$daily_internet_use)
chisq.test(hypertension_os_dataset$class, hypertension_os_dataset$available_vehicles)
chisq.test(hypertension_os_dataset$class, hypertension_os_dataset$military_service)
```

Feature the selection Skin Cancer using Chi-squared
```{r}
skin_cancer_set <- select(patients, gender, age, employment_status, education, marital_status, ancestry, available_vehicles, avg_commute,zipcode, children,daily_internet_use,military_service, skin_cancer)
FeatureTrain <- sample(nrow(skin_cancer_set), 0.7*nrow(skin_cancer_set), replace = FALSE)
FeatureTrainSet <- skin_cancer_set[FeatureTrain,]
FeatureTestSet <- skin_cancer_set[-FeatureTrain,]
response <- as.factor(patients$skin_cancer)
input <- select(patients, gender, age, employment_status, education, marital_status, ancestry, available_vehicles, avg_commute,zipcode, children,daily_internet_use,military_service)
data <- ubOver(X=input, Y=response)
skin_cancer_os_dataset <- cbind(data$X, class=data$Y)
chisq.test(skin_cancer_os_dataset$class, skin_cancer_os_dataset$gender)
chisq.test(skin_cancer_os_dataset$class, skin_cancer_os_dataset$age)
chisq.test(skin_cancer_os_dataset$class, skin_cancer_os_dataset$education)
chisq.test(skin_cancer_os_dataset$class, skin_cancer_os_dataset$marital_status)
chisq.test(skin_cancer_os_dataset$class, skin_cancer_os_dataset$zipcode)
chisq.test(skin_cancer_os_dataset$class, skin_cancer_os_dataset$employment_status)
chisq.test(skin_cancer_os_dataset$class, skin_cancer_os_dataset$children)
chisq.test(skin_cancer_os_dataset$class, skin_cancer_os_dataset$ancestry)
chisq.test(skin_cancer_os_dataset$class, skin_cancer_os_dataset$avg_commute)
chisq.test(skin_cancer_os_dataset$class, skin_cancer_os_dataset$daily_internet_use)
chisq.test(skin_cancer_os_dataset$class, skin_cancer_os_dataset$available_vehicles)
chisq.test(skin_cancer_os_dataset$class, skin_cancer_os_dataset$military_service)
```

## Predictive modeling

Now we need to predict the diseases and try to analyse the root causes

We can divide the into 3 steps 
1. Dealing with the Imbalance
2. Define algorithms
3. Testing algorithms

## Dealing with the Imbalance

From the exploratory analysis above the dependent variable is imbalanced. There are many alternatives to tackle this problem:
* Over-sampling
* Under-sampling
* Synthetic Minority Over-Sampling Technique (SMOTE) Sampling
* Cost Sensitive Learning

For this data set, will use over-sampling and SMOTE technique.

### Patients with alzheimers
```{r}
# Converting all the columns to factors
patients[] <- lapply( patients, factor) 
# - using the "[]" keeps the data frame structure
 col_names <- names(patients)
 patients[col_names] <- lapply(patients[col_names], factor)
 
# Bar plot analysis
barplot(table(patients$alzheimer), xlab=colnames(patients$alzheimer))

# Filter all the data and set Alzheimer as a target 
alzheimer_set <- select(patients, gender, age, employment_status, education, marital_status, ancestry, available_vehicles,zipcode, children,military_service, alzheimer)

# Splitting the into a train and test set into 70/30
train <- sample(nrow(alzheimer_set), 0.7*nrow(alzheimer_set), replace = FALSE)
  TrainSet <- alzheimer_set[train,]
  TestSet <- alzheimer_set[-train,]
  
response <- as.factor(patients$alzheimer)
input <- select(patients, gender, age, employment_status, education, marital_status, ancestry)
```

## Applying the Undersampling, oversampling, and smote to get a deep perspective of the data

## Using Logistic Regression, Randomforest, and Naive Bayes Models in the data set

```{r}
  # Initialize variables
  us_glm_accuracy <- c()
  us_glm_precision <- c()
  us_glm_recall <- c()
  us_glm_f1 <- c()
  
  os_glm_accuracy <- c()
  os_glm_precision <- c()
  os_glm_recall <- c()
  os_glm_f1 <- c()
  
  smote_glm_accuracy <- c()
  smote_glm_precision <- c()
  smote_glm_recall <- c()
  smote_glm_f1 <- c()
  
  us_rf_accuracy <- c()
  us_rf_precision <- c()
  us_rf_recall <- c()
  us_rf_f1 <- c()
  
  os_rf_accuracy <- c()
  os_rf_precision <- c()
  os_rf_recall <- c()
  os_rf_f1 <- c()
  
  smote_rf_accuracy <- c()
  smote_rf_precision <- c()
  smote_rf_recall <- c()
  smote_rf_f1 <- c()
  
  us_nb_accuracy <- c()
  us_nb_precision <- c()
  us_nb_recall <- c()
  us_nb_f1 <- c()
  
  os_nb_accuracy <- c()
  os_nb_precision <- c()
  os_nb_recall <- c()
  os_nb_f1 <- c()
  
  smote_nb_accuracy <- c()
  smote_nb_precision <- c()
  smote_nb_recall <- c()
  smote_nb_f1 <- c()
  
  # Using a 10-fold cross-validation and repeat the step 3 times
  train_control <- trainControl(method = "cv", number = 10)
  metric <- "Accuracy"
  mtry <- sqrt(ncol(alzheimer_set))
  tunegrid <- expand.grid(.mtry=mtry)    
```

# Fixing the iterations through sampling the model 10 times to get the best mean model for the prediction 
```{r}
for (i in 1:10) {
 }
    seed <- 999+i
    set.seed(seed)
    
    # Under sample
    ubUnder <- function(X=input, Y=response, k = 0, perc=40, method="percPos") {
}
    data <- ubUnder(X=input, Y=response, perc=40, method="percPos")
    us_dataset <- cbind(data$X, class=data$Y)
    
    # Over sample
       ubOver <- function(X=input, Y=response, k = 0, perc=40, method="percPos") {
}
    data <- ubOver(X=input, Y=response)
    os_dataset <- cbind(data$X, class=data$Y)
    
    # SMOTE
     ubSMOTE <- function(X=input, Y=response, k = 0, perc=40, method="percPos") {
}
    data <- ubSMOTE(X=input, Y=response)

# Using logistic regression for the under sampling
     ubUnder <- function(X=input, Y=response, k = 0, perc=40, method="percPos") {
}
    data <- ubUnder(X=input, Y=response, perc=40, method="percPos")
    us_dataset <- cbind(data$X, class=data$Y)
    glm_mod <- caret::train(class~. ,data=us_dataset, trControl = train_control, method="glm", family="binomial", tuneLength = 5)
    pred = predict(glm_mod, newdata=TestSet)
    us_cm <- confusionMatrix(data=pred, as.factor(TestSet$alzheimer), mode='everything')
    us_glm_accuracy <- c(us_glm_accuracy, us_cm$overall['Accuracy'])
    us_glm_precision <- c(us_glm_precision, us_cm$byClass['Precision'])
    us_glm_recall <- c(us_glm_recall, us_cm$byClass['Recall'])
    us_glm_f1 <- c(us_glm_f1, us_cm$byClass['F1'])
    
# Using logistic regression for the over sampling
     ubOver <- function(X=input, Y=response, k = 0, perc=40, method="percPos") {
}
    data <- ubOver(X=input, Y=response)
    os_dataset <- cbind(data$X, class=data$Y)
    glm_mod <- caret::train(class~.,data=os_dataset, trControl = train_control, method="glm", family="binomial", tuneLength = 5)
    pred = predict(glm_mod, newdata=TestSet)
    os_cm <- confusionMatrix(data=pred, as.factor(TestSet$alzheimer), mode='everything')
    os_glm_accuracy <- c(os_glm_accuracy, os_cm$overall['Accuracy'])
    os_glm_precision <- c(os_glm_precision, os_cm$byClass['Precision'])
    os_glm_recall <- c(os_glm_recall, os_cm$byClass['Recall'])
    os_glm_f1 <- c(os_glm_f1, os_cm$byClass['F1'])
    
# Using logistic regression for SMOTE
     ubSMOTE <- function(X=input, Y=response, k = 0, perc=40, method="percPos") {
}
    data <- ubSMOTE(X=input, Y=response)

    glm_mod <- caret::train(class~.,data=smote_dataset, trControl = train_control, method="glm", family="binomial", tuneLength = 5)
    pred = predict(glm_mod, newdata=TestSet)
    cm_smote <- confusionMatrix(data=pred, as.factor(TestSet$alzheimer), mode='everything')
    smote_glm_accuracy <- c(smote_glm_accuracy, cm_smote$overall['Accuracy'])
    smote_glm_precision <- c(smote_glm_precision, cm_smote$byClass['Precision'])
    smote_glm_recall <- c(smote_glm_recall, cm_smote$byClass['Recall'])
    smote_glm_f1 <- c(smote_glm_f1, cm_smote$byClass['F1'])
    
```

```{r}
    # Random forest for the under sampling
    rf_mod <- caret::train(class~., data=us_dataset, method="rf", metric=metric, tuneGrid=tunegrid, trControl=train_control)
    pred = predict(rf_mod, newdata=TestSet)
    us_cm <- confusionMatrix(data=pred, as.factor(TestSet$alzheimer), mode='everything')
    us_rf_accuracy <- c(us_rf_accuracy, us_cm$overall['Accuracy'])
    us_rf_precision <- c(us_rf_precision, us_cm$byClass['Precision'])
    us_rf_recall <- c(us_rf_recall, us_cm$byClass['Recall'])
    us_rf_f1 <- c(us_rf_f1, us_cm$byClass['F1'])
    
    # Random forest for the over sampling
    rf_mod <- caret::train(class~., data=os_dataset, method="rf", metric=metric, tuneGrid=tunegrid, trControl=train_control)
    pred = predict(rf_mod, newdata=TestSet)
    os_cm <- confusionMatrix(data=pred, as.factor(TestSet$alzheimer), mode='everything')
    os_rf_accuracy <- c(os_rf_accuracy, os_cm$overall['Accuracy'])
    os_rf_precision <- c(os_rf_precision, os_cm$byClass['Precision'])
    os_rf_recall <- c(os_rf_recall, os_cm$byClass['Recall'])
    os_rf_f1 <- c(os_rf_f1, os_cm$byClass['F1'])
    
    # Random forest for the smote
    rf_mod <- caret::train(class~., data=smote_dataset, method="rf", metric=metric, tuneGrid=tunegrid, trControl=train_control)
    pred = predict(rf_mod, newdata=TestSet)
    cm_smote <- confusionMatrix(data=pred, as.factor(TestSet$alzheimer), mode='everything')
    smote_rf_accuracy <- c(smote_rf_accuracy, cm_smote$overall['Accuracy'])
    smote_rf_precision <- c(smote_rf_precision, cm_smote$byClass['Precision'])
    smote_rf_recall <- c(smote_rf_recall, cm_smote$byClass['Recall'])
    smote_rf_f1 <- c(smote_rf_f1, cm_smote$byClass['F1'])
    
    # Naive byes for the under sampling
    nb_mod <- caret::train(class~., data=us_dataset, method="nb", trControl=train_control)
    pred = predict(nb_mod, newdata=TestSet)
    us_cm <- confusionMatrix(data=pred, as.factor(TestSet$alzheimer), mode='everything')
    us_nb_accuracy <- c(us_nb_accuracy, us_cm$overall['Accuracy'])
    us_nb_precision <- c(us_nb_precision, us_cm$byClass['Precision'])
    us_nb_recall <- c(us_nb_recall, us_cm$byClass['Recall'])
    us_nb_f1 <- c(us_nb_f1, us_cm$byClass['F1'])
    
    # Naive byes for the over sampling
    nb_mod <- caret::train(class~., data=os_dataset, method="nb", trControl=train_control)
    pred = predict(nb_mod, newdata=TestSet)
    os_cm <- confusionMatrix(data=pred, as.factor(TestSet$alzheimer), mode='everything')
    os_nb_accuracy <- c(os_nb_accuracy, os_cm$overall['Accuracy'])
    os_nb_precision <- c(os_nb_precision, os_cm$byClass['Precision'])
    os_nb_recall <- c(os_nb_recall, os_cm$byClass['Recall'])
    os_nb_f1 <- c(os_nb_f1, os_cm$byClass['F1'])
    
    # Naive byes for the smote
    nb_mod <- caret::train(class~., data=smote_dataset, method="nb", trControl=train_control)
    pred = predict(nb_mod, newdata=TestSet)
    cm_smote <- confusionMatrix(data=pred, as.factor(TestSet$alzheimer), mode='everything')
    smote_nb_accuracy <- c(smote_nb_accuracy, cm_smote$overall['Accuracy'])
    smote_nb_precision <- c(smote_nb_precision, cm_smote$byClass['Precision'])
    smote_nb_recall <- c(smote_nb_recall, cm_smote$byClass['Recall'])
    smote_nb_f1 <- c(smote_nb_f1, cm_smote$byClass['F1'])
```

## Alzheimer analysis

Data is partitioned into a test and training set using a 70/30 split
```{r}
df <- data.frame(us_glm_accuracy, os_glm_accuracy, smote_glm_accuracy, us_rf_accuracy, os_rf_accuracy, smote_rf_accuracy, us_nb_accuracy, os_nb_accuracy, smote_nb_accuracy)
us_glm_accuracy
os_glm_accuracy
smote_glm_accuracy
us_rf_accuracy
os_rf_accuracy
smote_rf_accuracy
us_nb_accuracy
os_nb_accuracy
smote_nb_accuracy
us_glm_precision
os_glm_precision
smote_glm_precision
us_rf_precision
os_rf_precision
smote_rf_precision
us_nb_precision
os_nb_precision
smote_nb_precision
us_glm_recall
os_glm_recall
smote_glm_recall
us_rf_recall
os_rf_recall
smote_rf_recall
us_nb_recall
os_nb_recall
smote_nb_recall
us_glm_f1
os_glm_f1
smote_glm_f1
us_rf_f1
os_rf_f1
smote_rf_f1
us_nb_f1
os_nb_f1
smote_nb_f1
c1 <- rainbow(10)
c2 <- rainbow(10, alpha=0.2)
c3 <- rainbow(10, v=0.7)
boxplot(df, col=c2, medcol=c3, whiskcol=c1, staplecol=c3, boxcol=c3, outcol=c3, pch=23, cex=2)
mean(us_nb_accuracy)
mean(us_nb_precision)
mean(us_nb_recall)
mean(us_nb_f1)
mean(os_nb_accuracy)
mean(os_nb_precision)
mean(os_nb_recall)
mean(os_nb_f1)
mean(smote_nb_accuracy)
mean(smote_nb_precision)
mean(smote_nb_recall)
mean(smote_nb_f1)
a <- matrix(
  c(mean(us_glm_accuracy),mean(us_glm_precision),mean(us_glm_recall),mean(us_glm_f1),
    mean(os_glm_accuracy),mean(os_glm_precision),mean(os_glm_recall),mean(os_glm_f1),
    mean(smote_glm_accuracy),mean(smote_glm_precision),mean(smote_glm_recall),mean(smote_glm_f1)),
  nrow=3,
  ncol=4,
  byrow = TRUE
)
a
```

### Patients with hypertension
```{r}
# Data before balancing
barplot(table(patients$hypertension), xlab=colnames(patients$hypertension))
# Filter the data set to make sure we have only hypertension disease as the target 
hypertension_set <- select(patients, gender, age, employment_status, education, marital_status, ancestry, available_vehicles, avg_commute,zipcode, children,daily_internet_use,military_service, hypertension)
# Data is partitioned into a test and training set using a 70/30 split
train <- sample(nrow(hypertension_set), 0.7*nrow(hypertension_set), replace = FALSE)
  TrainSet <- hypertension_set[train,]
  TestSet <- hypertension_set[-train,]
  
response <- as.factor(patients$hypertension)
input <- select(patients, gender, age, employment_status, education, marital_status, ancestry)
```

## Undersampling, oversampling, and smote against the test dataset

## Using Logistic Regression, Randomforest, and Naive Bayes Models in the data set 
```{r}
  # Initialize variables
  us_glm_accuracy <- c()
  us_glm_precision <- c()
  us_glm_recall <- c()
  us_glm_f1 <- c()
  
  os_glm_accuracy <- c()
  os_glm_precision <- c()
  os_glm_recall <- c()
  os_glm_f1 <- c()
  
  smote_glm_accuracy <- c()
  smote_glm_precision <- c()
  smote_glm_recall <- c()
  smote_glm_f1 <- c()
  
  us_rf_accuracy <- c()
  us_rf_precision <- c()
  us_rf_recall <- c()
  us_rf_f1 <- c()
  
  os_rf_accuracy <- c()
  os_rf_precision <- c()
  os_rf_recall <- c()
  os_rf_f1 <- c()
  
  smote_rf_accuracy <- c()
  smote_rf_precision <- c()
  smote_rf_recall <- c()
  smote_rf_f1 <- c()
  
  us_nb_accuracy <- c()
  us_nb_precision <- c()
  us_nb_recall <- c()
  us_nb_f1 <- c()
  
  os_nb_accuracy <- c()
  os_nb_precision <- c()
  os_nb_recall <- c()
  os_nb_f1 <- c()
  
  smote_nb_accuracy <- c()
  smote_nb_precision <- c()
  smote_nb_recall <- c()
  smote_nb_f1 <- c()
  
  # Using the 10-fold cross-validation and repeating the step 3 times
  train_control <- trainControl(method = "cv", number = 10)
  metric <- "Accuracy"
  mtry <- sqrt(ncol(alzheimer_set))
  tunegrid <- expand.grid(.mtry=mtry)    
```

```{r}
  # Iterating the sampling model 10 times to get the mean to get the best model for prediction
  for (i in 1:10) {
    
    # Under sampling
    ubUnder <- function(X= input, Y=response, perc=40, method="percPos"){
} 

    data <- ubUnder(X=input, Y=response, perc=40, method="percPos")
    us_dataset <- cbind(data$X, class=data$Y)
    
    # Over sampling
    ubOver <- function(X= input, Y=response, perc=40, method="percPos"){
} 

    data <- ubOver(X=input, Y=response)
    os_dataset <- cbind(data$X, class=data$Y)
    
    # SMOTE
    ubSMOTE <- function(X= input, Y=response, perc=40, method="percPos"){
} 

    data <- ubSMOTE(X=input, Y=response)
    smote_dataset <- cbind(data$X, class=data$Y)
    
    # Using the 10-fold cross-validation and repeating the step 3 times
    train_control <- trainControl(method = "repeatedcv", number = 10, repeats=3, savePredictions = TRUE)
    
    # Logistic regression for under sampling
    glm_mod <- caret::train(class~.,data=us_dataset, trControl = train_control, method="glm", family="binomial", tuneLength = 5)
    pred = predict(glm_mod, newdata=TestSet)
    us_cm <- confusionMatrix(data=pred, as.factor(TestSet$hypertension), mode='everything')
    us_glm_accuracy <- c(us_glm_accuracy, us_cm$overall['Accuracy'])
    us_glm_precision <- c(us_glm_precision, us_cm$byClass['Precision'])
    us_glm_recall <- c(us_glm_recall, us_cm$byClass['Recall'])
    us_glm_f1 <- c(us_glm_f1, us_cm$byClass['F1'])
    
    # Logistic regression for oversampling
    glm_mod <- caret::train(class~.,data=os_dataset, trControl = train_control, method="glm", family="binomial", tuneLength = 5)
    pred = predict(glm_mod, newdata=TestSet)
    os_cm <- confusionMatrix(data=pred, as.factor(TestSet$hypertension), mode='everything')
    os_glm_accuracy <- c(os_glm_accuracy, os_cm$overall['Accuracy'])
    os_glm_precision <- c(os_glm_precision, os_cm$byClass['Precision'])
    os_glm_recall <- c(os_glm_recall, os_cm$byClass['Recall'])
    os_glm_f1 <- c(os_glm_f1, os_cm$byClass['F1'])
    
    # Logistic regression for SMOTE
    glm_mod <- caret::train(class~.,data=smote_dataset, trControl = train_control, method="glm", family="binomial", tuneLength = 5)
    pred = predict(glm_mod, newdata=TestSet)
    cm_smote <- confusionMatrix(data=pred, as.factor(TestSet$hypertension), mode='everything')
    smote_glm_accuracy <- c(smote_glm_accuracy, cm_smote$overall['Accuracy'])
    smote_glm_precision <- c(smote_glm_precision, cm_smote$byClass['Precision'])
    smote_glm_recall <- c(smote_glm_recall, cm_smote$byClass['Recall'])
    smote_glm_f1 <- c(smote_glm_f1, cm_smote$byClass['F1'])
    
    # Random forest for under sampling
    rf_mod <- caret::train(class~., data=us_dataset, method="rf", metric=metric, tuneGrid=tunegrid, trControl=train_control)
    pred = predict(rf_mod, newdata=TestSet)
    us_cm <- confusionMatrix(data=pred, as.factor(TestSet$hypertension), mode='everything')
    us_rf_accuracy <- c(us_rf_accuracy, us_cm$overall['Accuracy'])
    us_rf_precision <- c(us_rf_precision, us_cm$byClass['Precision'])
    us_rf_recall <- c(us_rf_recall, us_cm$byClass['Recall'])
    us_rf_f1 <- c(us_rf_f1, us_cm$byClass['F1'])
    
    # Random forest for over sampling
    rf_mod <- caret::train(class~., data=os_dataset, method="rf", metric=metric, tuneGrid=tunegrid, trControl=train_control)
    pred = predict(rf_mod, newdata=TestSet)
    os_cm <- confusionMatrix(data=pred, as.factor(TestSet$hypertension), mode='everything')
    os_rf_accuracy <- c(os_rf_accuracy, os_cm$overall['Accuracy'])
    os_rf_precision <- c(os_rf_precision, os_cm$byClass['Precision'])
    os_rf_recall <- c(os_rf_recall, os_cm$byClass['Recall'])
    os_rf_f1 <- c(os_rf_f1, os_cm$byClass['F1'])
    
    # Random forest for SMOTE
    rf_mod <- caret::train(class~., data=smote_dataset, method="rf", metric=metric, tuneGrid=tunegrid, trControl=train_control)
    pred = predict(rf_mod, newdata=TestSet)
    cm_smote <- confusionMatrix(data=pred, as.factor(TestSet$hypertension), mode='everything')
    smote_rf_accuracy <- c(smote_rf_accuracy, cm_smote$overall['Accuracy'])
    smote_rf_precision <- c(smote_rf_precision, cm_smote$byClass['Precision'])
    smote_rf_recall <- c(smote_rf_recall, cm_smote$byClass['Recall'])
    smote_rf_f1 <- c(smote_rf_f1, cm_smote$byClass['F1'])
    
    # Naive byes for under sampling
    nb_mod <- caret::train(class~., data=us_dataset, method="nb", trControl=train_control)
    pred = predict(nb_mod, newdata=TestSet)
    us_cm <- confusionMatrix(data=pred, as.factor(TestSet$hypertension), mode='everything')
    us_nb_accuracy <- c(us_nb_accuracy, us_cm$overall['Accuracy'])
    us_nb_precision <- c(us_nb_precision, us_cm$byClass['Precision'])
    us_nb_recall <- c(us_nb_recall, us_cm$byClass['Recall'])
    us_nb_f1 <- c(us_nb_f1, us_cm$byClass['F1'])
    
    # Naive byes for oversampling
    nb_mod <- caret::train(class~., data=os_dataset, method="nb", trControl=train_control)
    pred = predict(nb_mod, newdata=TestSet)
    os_cm <- confusionMatrix(data=pred, as.factor(TestSet$hypertension), mode='everything')
    os_nb_accuracy <- c(os_nb_accuracy, os_cm$overall['Accuracy'])
    os_nb_precision <- c(os_nb_precision, os_cm$byClass['Precision'])
    os_nb_recall <- c(os_nb_recall, os_cm$byClass['Recall'])
    os_nb_f1 <- c(os_nb_f1, os_cm$byClass['F1'])
    
    # Naive byes for SMOTE
    nb_mod <- caret::train(class~., data=smote_dataset, method="nb", trControl=train_control)
    pred = predict(nb_mod, newdata=TestSet)
    cm_smote <- confusionMatrix(data=pred, as.factor(TestSet$hypertension), mode='everything')
    smote_nb_accuracy <- c(smote_nb_accuracy, cm_smote$overall['Accuracy'])
    smote_nb_precision <- c(smote_nb_precision, cm_smote$byClass['Precision'])
    smote_nb_recall <- c(smote_nb_recall, cm_smote$byClass['Recall'])
    smote_nb_f1 <- c(smote_nb_f1, cm_smote$byClass['F1'])
  }
  
```


## Hypertension analysis

Data is partitioned into a test and training set using a 70/30 split
```{r}
df <- data.frame(us_glm_accuracy, os_glm_accuracy, smote_glm_accuracy, us_rf_accuracy, os_rf_accuracy, smote_rf_accuracy, us_nb_accuracy, os_nb_accuracy, smote_nb_accuracy)
us_glm_accuracy
os_glm_accuracy
smote_glm_accuracy
us_rf_accuracy
os_rf_accuracy
smote_rf_accuracy
us_nb_accuracy
os_nb_accuracy
smote_nb_accuracy
us_glm_precision
os_glm_precision
smote_glm_precision
us_rf_precision
os_rf_precision
smote_rf_precision
us_nb_precision
os_nb_precision
smote_nb_precision
us_glm_recall
os_glm_recall
smote_glm_recall
us_rf_recall
os_rf_recall
smote_rf_recall
us_nb_recall
os_nb_recall
smote_nb_recall
us_glm_f1
os_glm_f1
smote_glm_f1
us_rf_f1
os_rf_f1
smote_rf_f1
us_nb_f1
os_nb_f1
smote_nb_f1
c1 <- rainbow(10)
c2 <- rainbow(10, alpha=0.2)
c3 <- rainbow(10, v=0.7)
boxplot(df, col=c2, medcol=c3, whiskcol=c1, staplecol=c3, boxcol=c3, outcol=c3, pch=23, cex=2)
mean(us_nb_accuracy)
mean(us_nb_precision)
mean(us_nb_recall)
mean(us_nb_f1)
mean(os_nb_accuracy)
mean(os_nb_precision)
mean(os_nb_recall)
mean(os_nb_f1)
mean(smote_nb_accuracy)
mean(smote_nb_precision)
mean(smote_nb_recall)
mean(smote_nb_f1)
a <- matrix(
  c(mean(us_glm_accuracy),mean(us_glm_precision),mean(us_glm_recall),mean(us_glm_f1),
    mean(os_glm_accuracy),mean(os_glm_precision),mean(os_glm_recall),mean(os_glm_f1),
    mean(smote_glm_accuracy),mean(smote_glm_precision),mean(smote_glm_recall),mean(smote_glm_f1)),
  nrow=3,
  ncol=4,
  byrow = TRUE
)
a
```


### Patients with skin cancer

```{r}
# Data before balancing
barplot(table(patients$skin_cancer), xlab=colnames(patients$skin_cancer))

# Filtering the data set to have only skin_cancer disease as the target 
skin_cancer_set <- select(patients, gender, age, employment_status, education, marital_status, ancestry, available_vehicles, avg_commute,zipcode, children,daily_internet_use,military_service, skin_cancer)

# Data is partitioned into a test and training set using a 70/30 split
train <- sample(nrow(skin_cancer_set), 0.7*nrow(skin_cancer_set), replace = FALSE)
  TrainSet <- skin_cancer_set[train,]
  TestSet <- skin_cancer_set[-train,]
  
response <- as.factor(patients$skin_cancer)
input <- select(patients, gender, age, employment_status, education, marital_status, ancestry)
```

## Undersampling, oversampling, and smote against the test dataset

## Using Logistic Regression, Randomforest, and Naive Bayes Models in the data set
```{r}
  # Initialize variables
  us_glm_accuracy <- c()
  us_glm_precision <- c()
  us_glm_recall <- c()
  us_glm_f1 <- c()
  
  os_glm_accuracy <- c()
  os_glm_precision <- c()
  os_glm_recall <- c()
  os_glm_f1 <- c()
  
  smote_glm_accuracy <- c()
  smote_glm_precision <- c()
  smote_glm_recall <- c()
  smote_glm_f1 <- c()
  
  us_rf_accuracy <- c()
  us_rf_precision <- c()
  us_rf_recall <- c()
  us_rf_f1 <- c()
  
  os_rf_accuracy <- c()
  os_rf_precision <- c()
  os_rf_recall <- c()
  os_rf_f1 <- c()
  
  smote_rf_accuracy <- c()
  smote_rf_precision <- c()
  smote_rf_recall <- c()
  smote_rf_f1 <- c()
  
  us_nb_accuracy <- c()
  us_nb_precision <- c()
  us_nb_recall <- c()
  us_nb_f1 <- c()
  
  os_nb_accuracy <- c()
  os_nb_precision <- c()
  os_nb_recall <- c()
  os_nb_f1 <- c()
  
  smote_nb_accuracy <- c()
  smote_nb_precision <- c()
  smote_nb_recall <- c()
  smote_nb_f1 <- c()
  
  # Using the 10-fold cross-validation and repeating the step 3 times
  train_control <- trainControl(method = "cv", number = 10)
  metric <- "Accuracy"
  mtry <- sqrt(ncol(skin_cancer_set))
  tunegrid <- expand.grid(.mtry=mtry)    
```

```{r}
  # Iterating the sampling model 10 times to get the mean to get the best model for prediction
  for (i in 1:10) {
    
    # Under sampling
    ubUnder <- function(X= input, Y=response, perc=40, method="percPos"){
} 
    data <- ubUnder(X=input, Y=response, perc=40, method="percPos")
    us_dataset <- cbind(data$X, class=data$Y)
    
    # Over sampling
    ubOver <- function(X= input, Y=response, perc=40, method="percPos"){
}
    data <- ubOver(X=input, Y=response)
    os_dataset <- cbind(data$X, class=data$Y)
    
    # SMOTE
    ubSMOTE <- function(X= input, Y=response, perc=40, method="percPos"){
}
    data <- ubSMOTE(X=input, Y=response)
    smote_dataset <- cbind(data$X, class=data$Y)
    
    # Using the 10-fold cross-validation and repeating the step 3 times
    train_control <- trainControl(method = "repeatedcv", number = 10, repeats=3, savePredictions = TRUE)
    
    # Logistic regression for under sampling
    glm_mod <- caret::train(class~.,data=us_dataset, trControl = train_control, method="glm", family="binomial", tuneLength = 5)
    pred = predict(glm_mod, newdata=TestSet)
    us_cm <- confusionMatrix(data=pred, as.factor(TestSet$skin_cancer), mode='everything')
    us_glm_accuracy <- c(us_glm_accuracy, us_cm$overall['Accuracy'])
    us_glm_precision <- c(us_glm_precision, us_cm$byClass['Precision'])
    us_glm_recall <- c(us_glm_recall, us_cm$byClass['Recall'])
    us_glm_f1 <- c(us_glm_f1, us_cm$byClass['F1'])
    
    # Logistic regression for oversampling
    glm_mod <- caret::train(class~.,data=os_dataset, trControl = train_control, method="glm", family="binomial", tuneLength = 5)
    pred = predict(glm_mod, newdata=TestSet)
    os_cm <- confusionMatrix(data=pred, as.factor(TestSet$skin_cancer), mode='everything')
    os_glm_accuracy <- c(os_glm_accuracy, os_cm$overall['Accuracy'])
    os_glm_precision <- c(os_glm_precision, os_cm$byClass['Precision'])
    os_glm_recall <- c(os_glm_recall, os_cm$byClass['Recall'])
    os_glm_f1 <- c(os_glm_f1, os_cm$byClass['F1'])
    
    # Logistic regression for SMOTE
    glm_mod <- caret::train(class~.,data=smote_dataset, trControl = train_control, method="glm", family="binomial", tuneLength = 5)
    pred = predict(glm_mod, newdata=TestSet)
    cm_smote <- confusionMatrix(data=pred, as.factor(TestSet$skin_cancer), mode='everything')
    smote_glm_accuracy <- c(smote_glm_accuracy, cm_smote$overall['Accuracy'])
    smote_glm_precision <- c(smote_glm_precision, cm_smote$byClass['Precision'])
    smote_glm_recall <- c(smote_glm_recall, cm_smote$byClass['Recall'])
    smote_glm_f1 <- c(smote_glm_f1, cm_smote$byClass['F1'])
    
    # Random forest for under sampling
    rf_mod <- caret::train(class~., data=us_dataset, method="rf", metric=metric, tuneGrid=tunegrid, trControl=train_control)
    pred = predict(rf_mod, newdata=TestSet)
    us_cm <- confusionMatrix(data=pred, as.factor(TestSet$skin_cancer), mode='everything')
    us_rf_accuracy <- c(us_rf_accuracy, us_cm$overall['Accuracy'])
    us_rf_precision <- c(us_rf_precision, us_cm$byClass['Precision'])
    us_rf_recall <- c(us_rf_recall, us_cm$byClass['Recall'])
    us_rf_f1 <- c(us_rf_f1, us_cm$byClass['F1'])
    
    # Random forest for over sampling
    rf_mod <- caret::train(class~., data=os_dataset, method="rf", metric=metric, tuneGrid=tunegrid, trControl=train_control)
    pred = predict(rf_mod, newdata=TestSet)
    os_cm <- confusionMatrix(data=pred, as.factor(TestSet$skin_cancer), mode='everything')
    os_rf_accuracy <- c(os_rf_accuracy, os_cm$overall['Accuracy'])
    os_rf_precision <- c(os_rf_precision, os_cm$byClass['Precision'])
    os_rf_recall <- c(os_rf_recall, os_cm$byClass['Recall'])
    os_rf_f1 <- c(os_rf_f1, os_cm$byClass['F1'])
    
    # Random forest for SMOTE
    rf_mod <- caret::train(class~., data=smote_dataset, method="rf", metric=metric, tuneGrid=tunegrid, trControl=train_control)
    pred = predict(rf_mod, newdata=TestSet)
    cm_smote <- confusionMatrix(data=pred, as.factor(TestSet$skin_cancer), mode='everything')
    smote_rf_accuracy <- c(smote_rf_accuracy, cm_smote$overall['Accuracy'])
    smote_rf_precision <- c(smote_rf_precision, cm_smote$byClass['Precision'])
    smote_rf_recall <- c(smote_rf_recall, cm_smote$byClass['Recall'])
    smote_rf_f1 <- c(smote_rf_f1, cm_smote$byClass['F1'])
    
    # Naive bayes for under sampling
    nb_mod <- caret::train(class~., data=us_dataset, method="nb", trControl=train_control)
    pred = predict(nb_mod, newdata=TestSet)
    us_cm <- confusionMatrix(data=pred, as.factor(TestSet$skin_cancer), mode='everything')
    us_nb_accuracy <- c(us_nb_accuracy, us_cm$overall['Accuracy'])
    us_nb_precision <- c(us_nb_precision, us_cm$byClass['Precision'])
    us_nb_recall <- c(us_nb_recall, us_cm$byClass['Recall'])
    us_nb_f1 <- c(us_nb_f1, us_cm$byClass['F1'])
    
    # Naive bayes for over sampling
    nb_mod <- caret::train(class~., data=os_dataset, method="nb", trControl=train_control)
    pred = predict(nb_mod, newdata=TestSet)
    os_cm <- confusionMatrix(data=pred, as.factor(TestSet$skin_cancer), mode='everything')
    os_nb_accuracy <- c(os_nb_accuracy, os_cm$overall['Accuracy'])
    os_nb_precision <- c(os_nb_precision, os_cm$byClass['Precision'])
    os_nb_recall <- c(os_nb_recall, os_cm$byClass['Recall'])
    os_nb_f1 <- c(os_nb_f1, os_cm$byClass['F1'])
    
    # Naive bayes for SMOTE
    nb_mod <- caret::train(class~., data=smote_dataset, method="nb", trControl=train_control)
    pred = predict(nb_mod, newdata=TestSet)
    cm_smote <- confusionMatrix(data=pred, as.factor(TestSet$skin_cancer), mode='everything')
    smote_nb_accuracy <- c(smote_nb_accuracy, cm_smote$overall['Accuracy'])
    smote_nb_precision <- c(smote_nb_precision, cm_smote$byClass['Precision'])
    smote_nb_recall <- c(smote_nb_recall, cm_smote$byClass['Recall'])
    smote_nb_f1 <- c(smote_nb_f1, cm_smote$byClass['F1'])
  }
  
```


## Skin cancer analysis

Data is partitioned into a test and training set using a 70/30 split
```{r}
df <- data.frame(us_glm_accuracy, os_glm_accuracy, smote_glm_accuracy, us_rf_accuracy, os_rf_accuracy, smote_rf_accuracy, us_nb_accuracy, os_nb_accuracy, smote_nb_accuracy)
us_glm_accuracy
os_glm_accuracy
smote_glm_accuracy
us_rf_accuracy
os_rf_accuracy
smote_rf_accuracy
us_nb_accuracy
os_nb_accuracy
smote_nb_accuracy
us_glm_precision
os_glm_precision
smote_glm_precision
us_rf_precision
os_rf_precision
smote_rf_precision
us_nb_precision
os_nb_precision
smote_nb_precision
us_glm_recall
os_glm_recall
smote_glm_recall
us_rf_recall
os_rf_recall
smote_rf_recall
us_nb_recall
os_nb_recall
smote_nb_recall
us_glm_f1
os_glm_f1
smote_glm_f1
us_rf_f1
os_rf_f1
smote_rf_f1
us_nb_f1
os_nb_f1
smote_nb_f1
c1 <- rainbow(10)
c2 <- rainbow(10, alpha=0.2)
c3 <- rainbow(10, v=0.7)
boxplot(df, col=c2, medcol=c3, whiskcol=c1, staplecol=c3, boxcol=c3, outcol=c3, pch=23, cex=2)
mean(us_nb_accuracy)
mean(us_nb_precision)
mean(us_nb_recall)
mean(us_nb_f1)
mean(os_nb_accuracy)
mean(os_nb_precision)
mean(os_nb_recall)
mean(os_nb_f1)
mean(smote_nb_accuracy)
mean(smote_nb_precision)
mean(smote_nb_recall)
mean(smote_nb_f1)
a <- matrix(
  c(mean(us_glm_accuracy),mean(us_glm_precision),mean(us_glm_recall),mean(us_glm_f1),
    mean(os_glm_accuracy),mean(os_glm_precision),mean(os_glm_recall),mean(os_glm_f1),
    mean(smote_glm_accuracy),mean(smote_glm_precision),mean(smote_glm_recall),mean(smote_glm_f1)),
  nrow=3,
  ncol=4,
  byrow = TRUE
)
a
```
